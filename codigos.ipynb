{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef8edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cliente\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyogrio\\raw.py:198: RuntimeWarning: data/PRODES_AMZ_Municipal_2023.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas encontradas no shapefile:\n",
      "Index(['fid', 'state', 'path_row', 'main_class', 'class_name', 'sub_class',\n",
      "       'def_cloud', 'julian_day', 'image_date', 'year', 'area_km', 'scene_id',\n",
      "       'source', 'satellite', 'sensor', 'uuid', 'geometry'],\n",
      "      dtype='object')\n",
      "✅ Arquivo CSV agregado salvo com sucesso em data/desmatamento_por_estado.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do shapefile\n",
    "caminho = \"data/PRODES_AMZ_Municipal_2023.shp\"\n",
    "\n",
    "# Ler o shapefile\n",
    "gdf = gpd.read_file(caminho)\n",
    "\n",
    "print(\"Colunas encontradas no shapefile:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "\n",
    "# Agrupar por estado e ano, somando área total desmatada\n",
    "# Salvar como CSV\n",
    "\n",
    "gdf.to_csv('data/desmatamento_por_estado.csv', index=False)\n",
    "\n",
    "print(\"✅ Arquivo CSV agregado salvo com sucesso em data/desmatamento_por_estado.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977d8748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PIB municipal salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://apisidra.ibge.gov.br/values/t/5938/n6/all/v/37/p/2021\"\n",
    "df = pd.read_json(url)\n",
    "df.to_csv(\"data/pib_municipal_2021.csv\", index=False)\n",
    "\n",
    "url = \"https://apisidra.ibge.gov.br/values/t/5938/n6/all/v/37/p/2020\"\n",
    "df = pd.read_json(url)\n",
    "df.to_csv(\"data/pib_municipal_2020.csv\", index=False)\n",
    "\n",
    "url = \"https://apisidra.ibge.gov.br/values/t/5938/n6/all/v/37/p/2019\"\n",
    "df = pd.read_json(url)\n",
    "df.to_csv(\"data/pib_municipal_2019.csv\", index=False)\n",
    "\n",
    "url = \"https://apisidra.ibge.gov.br/values/t/5938/n6/all/v/37/p/2018\"\n",
    "df = pd.read_json(url)\n",
    "df.to_csv(\"data/pib_municipal_2018.csv\", index=False)\n",
    "\n",
    "url = \"https://apisidra.ibge.gov.br/values/t/5938/n6/all/v/37/p/2017\"\n",
    "df = pd.read_json(url)\n",
    "df.to_csv(\"data/pib_municipal_2017.csv\", index=False)\n",
    "\n",
    "print(\"✅ PIB municipal salvo com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf688ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/desmatamento_por_estado.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/limpos\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1️⃣ Ler a base\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaminho\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Base carregada com sucesso!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📊 Linhas:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/desmatamento_por_estado.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho da base original\n",
    "caminho = \"data/desmatamento_por_estado.csv\"\n",
    "\n",
    "# Criar pasta de saída\n",
    "os.makedirs(\"data/limpos\", exist_ok=True)\n",
    "\n",
    "# 1️⃣ Ler a base\n",
    "df = pd.read_csv(caminho)\n",
    "print(\"✅ Base carregada com sucesso!\")\n",
    "print(\"📊 Linhas:\", len(df))\n",
    "\n",
    "# 2️⃣ Manter apenas colunas importantes\n",
    "colunas_importantes = [\n",
    "    \"fid\",\n",
    "    \"state\",\n",
    "    \"image_date\",\n",
    "    \"area_km\"\n",
    "]\n",
    "df = df[colunas_importantes]\n",
    "print(\"🔹 Colunas mantidas:\", list(df.columns))\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"state\": \"UF\"\n",
    "})\n",
    "# 3️⃣ Corrigir tipos de dados\n",
    "df[\"area_km\"] = pd.to_numeric(df[\"area_km\"], errors=\"coerce\")\n",
    "df[\"image_date\"] = pd.to_datetime(df[\"image_date\"], errors=\"coerce\")\n",
    "\n",
    "# 4️⃣ Filtrar apenas registros de 2021 (sem criar coluna year permanente)\n",
    "df = df.loc[df[\"image_date\"].dt.year == 2021 or df[\"image_date\"].dt.year == 2020 or df[\"image_date\"].dt.year == 2019 or df[\"image_date\"].dt.year == 2018 or df[\"image_date\"].dt.year == 2017 ]\n",
    "\n",
    "# 5️⃣ Remover linhas com dados inválidos\n",
    "df = df.dropna(subset=[\"area_km\", \"image_date\"])\n",
    "# 6️⃣ Agregar total de área desmatada por estado\n",
    "df_estado = df.groupby(\"UF\", as_index=False)[\"area_km\"].sum()\n",
    "\n",
    "# 7️⃣ Salvar versão agregada\n",
    "output = \"data/limpos/desmatamento_2021_por_estado.csv\"\n",
    "df_estado.to_csv(output, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Base agregada por estado salva com sucesso!\")\n",
    "print(df_estado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a36343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base carregada com sucesso!\n",
      "📊 Linhas: 5571\n",
      "🌳 Estados filtrados (Amazônia Legal): ['AC', 'AM', 'AP', 'MA', 'MT', 'PA', 'RO', 'RR', 'TO']\n",
      "✅ PIB estadual da Amazônia Legal salvo com sucesso!\n",
      "   UF  pib_mil_reais  pib_bilhoes   Ano\n",
      "0  AC     14272939.0        14.27  2017\n",
      "1  AM     93240190.0        93.24  2017\n",
      "2  AP     15481909.0        15.48  2017\n",
      "3  MA     89542756.0        89.54  2017\n",
      "4  MT    126845895.0       126.85  2017\n",
      "5  PA    155232405.0       155.23  2017\n",
      "6  RO     43516144.0        43.52  2017\n",
      "7  RR     12104706.0        12.10  2017\n",
      "8  TO     34108132.0        34.11  2017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Caminho do arquivo original\n",
    "caminho = \"data/pib_municipal_2017.csv\"\n",
    "\n",
    "# Criar pasta de saída\n",
    "os.makedirs(\"data/limpos\", exist_ok=True)\n",
    "\n",
    "# 1️⃣ Ler a base de PIB municipal\n",
    "df = pd.read_csv(caminho, encoding=\"utf-8\")\n",
    "print(\"✅ Base carregada com sucesso!\")\n",
    "print(\"📊 Linhas:\", len(df))\n",
    "\n",
    "# 2️⃣ Renomear colunas relevantes\n",
    "df = df.rename(columns={\n",
    "    \"V\": \"pib_mil_reais\",\n",
    "    \"D1N\": \"municipio\",\n",
    "    \"Ano\": \"ano\"\n",
    "})\n",
    "\n",
    "# 3️⃣ Extrair a sigla do estado a partir do nome do município\n",
    "df[\"UF\"] = df[\"municipio\"].apply(\n",
    "    lambda x: re.search(r\"-\\s*([A-Z]{2})$\", x).group(1)\n",
    "    if isinstance(x, str) and re.search(r\"-\\s*([A-Z]{2})$\", x)\n",
    "    else None\n",
    ")\n",
    "\n",
    "# 4️⃣ Converter valores para numérico\n",
    "df[\"pib_mil_reais\"] = pd.to_numeric(df[\"pib_mil_reais\"], errors=\"coerce\")\n",
    "\n",
    "# 5️⃣ Filtrar apenas estados da Amazônia Legal\n",
    "amazonia_legal = [\"AC\", \"AM\", \"AP\", \"MA\", \"MT\", \"PA\", \"RO\", \"RR\", \"TO\"]\n",
    "df = df[df[\"UF\"].isin(amazonia_legal)]\n",
    "\n",
    "print(\"🌳 Estados filtrados (Amazônia Legal):\", sorted(df[\"UF\"].unique()))\n",
    "\n",
    "# 6️⃣ Agrupar por estado e somar PIB\n",
    "pib_estadual = df.groupby(\"UF\", as_index=False)[\"pib_mil_reais\"].sum()\n",
    "\n",
    "# 7️⃣ Adicionar PIB em bilhões para facilitar leitura\n",
    "pib_estadual[\"pib_bilhoes\"] = (pib_estadual[\"pib_mil_reais\"] / 1_000_000).round(2)\n",
    "pib_estadual[\"Ano\"] = 2017\n",
    "# 8️⃣ Salvar resultado\n",
    "output = \"data/limpos/pib_estadual_amazonia_2017.csv\"\n",
    "pib_estadual.to_csv(output, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ PIB estadual da Amazônia Legal salvo com sucesso!\")\n",
    "print(pib_estadual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cdbe797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base carregada com sucesso!\n",
      "📊 Linhas: 174388\n",
      "🔹 Colunas mantidas: ['ano', 'sigla_uf', 'populacao']\n",
      "✅ Base agregada por estado salva com sucesso!\n",
      "    UF   ano  populacao\n",
      "0   AC  2017   829619.0\n",
      "1   AC  2018   869265.0\n",
      "2   AC  2019   881935.0\n",
      "3   AC  2020   894470.0\n",
      "4   AC  2021   906876.0\n",
      "5   AM  2017  4063614.0\n",
      "6   AM  2018  4080611.0\n",
      "7   AM  2019  4144597.0\n",
      "8   AM  2020  4207714.0\n",
      "9   AM  2021  4269995.0\n",
      "10  AP  2017   797722.0\n",
      "11  AP  2018   829494.0\n",
      "12  AP  2019   845731.0\n",
      "13  AP  2020   861773.0\n",
      "14  AP  2021   877613.0\n",
      "15  MA  2017  7000229.0\n",
      "16  MA  2018  7035055.0\n",
      "17  MA  2019  7075181.0\n",
      "18  MA  2020  7114598.0\n",
      "19  MA  2021  7153262.0\n",
      "20  MT  2017  3344544.0\n",
      "21  MT  2018  3441998.0\n",
      "22  MT  2019  3484466.0\n",
      "23  MT  2020  3526220.0\n",
      "24  MT  2021  3567234.0\n",
      "25  PA  2017  8366628.0\n",
      "26  PA  2018  8513497.0\n",
      "27  PA  2019  8602865.0\n",
      "28  PA  2020  8690745.0\n",
      "29  PA  2021  8777124.0\n",
      "30  RO  2017  1805788.0\n",
      "31  RO  2018  1757589.0\n",
      "32  RO  2019  1777225.0\n",
      "33  RO  2020  1796460.0\n",
      "34  RO  2021  1815278.0\n",
      "35  RR  2017   522636.0\n",
      "36  RR  2018   576568.0\n",
      "37  RR  2019   605761.0\n",
      "38  RR  2020   631181.0\n",
      "39  RR  2021   652713.0\n",
      "40  TO  2017  1550194.0\n",
      "41  TO  2018  1555229.0\n",
      "42  TO  2019  1572866.0\n",
      "43  TO  2020  1590248.0\n",
      "44  TO  2021  1607363.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho da base original\n",
    "caminho = \"data/br_ibge_populacao_municipio.csv\"\n",
    "\n",
    "# Criar pasta de saída\n",
    "os.makedirs(\"data/limpos\", exist_ok=True)\n",
    "\n",
    "# 1️⃣ Ler a base\n",
    "df = pd.read_csv(caminho)\n",
    "print(\"✅ Base carregada com sucesso!\")\n",
    "print(\"📊 Linhas:\", len(df))\n",
    "\n",
    "# 2️⃣ Manter apenas colunas importantes\n",
    "colunas_importantes = [\n",
    "    \"ano\",\n",
    "    \"sigla_uf\",\n",
    "    \"populacao\"\n",
    "]\n",
    "df = df[colunas_importantes]\n",
    "print(\"🔹 Colunas mantidas:\", list(df.columns))\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"sigla_uf\": \"UF\"\n",
    "})\n",
    "# 3️⃣ Corrigir tipos de dados\n",
    "df[\"ano\"] = pd.to_numeric(df[\"ano\"], errors=\"coerce\")\n",
    "df[\"populacao\"] = pd.to_numeric(df[\"populacao\"], errors=\"coerce\")\n",
    "\n",
    "# 4️⃣ Filtrar apenas registros de 2021 (sem criar coluna year permanente)\n",
    "df = df.loc[(df[\"ano\"] >= 2017) & (df[\"ano\"] <= 2021)]\n",
    "\n",
    "# 5️⃣ Remover linhas com dados inválidos\n",
    "df = df.dropna(subset=[\"populacao\"])\n",
    "\n",
    "amazonia_legal = [\"AC\", \"AM\", \"AP\", \"MA\", \"MT\", \"PA\", \"RO\", \"RR\", \"TO\"]\n",
    "df= df[df[\"UF\"].isin(amazonia_legal)]\n",
    "# 6️⃣ Agregar total de área desmatada por estado\n",
    "df_estado = df.groupby([\"UF\",\"ano\"], as_index=False)[\"populacao\"].sum()\n",
    "\n",
    "\n",
    "# 7️⃣ Salvar versão agregada\n",
    "output = \"data/limpos/br_ibge_populacao_estados_limpo.csv\"\n",
    "df_estado.to_csv(output, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Base agregada por estado salva com sucesso!\")\n",
    "print(df_estado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1258f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base carregada com sucesso!\n",
      "📊 Linhas: 27\n",
      "🔹 Colunas mantidas: ['Sigla', '2017', '2018', '2019', '2020', '2021']\n",
      "✅ Base agregada por estado salva com sucesso!\n",
      "    UF  IDH2017  IDH2018  IDH2019  IDH2020  IDH2021\n",
      "0   AC    0.712    0.733    0.739    0.746    0.710\n",
      "2   AM    0.728    0.718    0.726    0.727    0.700\n",
      "3   AP    0.732    0.741    0.737    0.724    0.688\n",
      "9   MA    0.685    0.686    0.694    0.699    0.676\n",
      "12  MT    0.770    0.778    0.779    0.756    0.736\n",
      "13  PA    0.694    0.707    0.704    0.719    0.690\n",
      "20  RO    0.721    0.730    0.730    0.739    0.700\n",
      "21  RR    0.746    0.760    0.749    0.739    0.699\n",
      "26  TO    0.740    0.749    0.751    0.755    0.731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho da base original\n",
    "caminho = \"data/ipeadata[24-10-2025-01-26].csv\"\n",
    "\n",
    "# Criar pasta de saída\n",
    "os.makedirs(\"data/limpos\", exist_ok=True)\n",
    "\n",
    "# 1️⃣ Ler a base\n",
    "\n",
    "df = pd.read_csv(\n",
    "    caminho,\n",
    "    skiprows=1\n",
    ")\n",
    "print(\"✅ Base carregada com sucesso!\")\n",
    "print(\"📊 Linhas:\", len(df))\n",
    "\n",
    "# 2️⃣ Manter apenas colunas importantes\n",
    "colunas_importantes = [\n",
    "    \"Sigla\",\n",
    "    \"2017\",\n",
    "    \"2018\",\n",
    "    \"2019\",\n",
    "    \"2020\",\n",
    "    \"2021\"\n",
    "]\n",
    "df = df[colunas_importantes]\n",
    "print(\"🔹 Colunas mantidas:\", list(df.columns))\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"Sigla\": \"UF\",\n",
    "    \"2017\": \"IDH2017\",\n",
    "    \"2018\": \"IDH2018\",\n",
    "    \"2019\": \"IDH2019\",\n",
    "    \"2020\": \"IDH2020\",\n",
    "    \"2021\": \"IDH2021\"\n",
    "})\n",
    "# 3️⃣ Corrigir tipos de dados\n",
    "df[\"IDH2017\"] = pd.to_numeric(df[\"IDH2017\"], errors=\"coerce\")\n",
    "df[\"IDH2018\"] = pd.to_numeric(df[\"IDH2018\"], errors=\"coerce\")\n",
    "df[\"IDH2019\"] = pd.to_numeric(df[\"IDH2019\"], errors=\"coerce\")\n",
    "df[\"IDH2020\"] = pd.to_numeric(df[\"IDH2020\"], errors=\"coerce\")\n",
    "df[\"IDH2021\"] = pd.to_numeric(df[\"IDH2021\"], errors=\"coerce\")\n",
    "\n",
    "# 5️⃣ Remover linhas com dados inválidos\n",
    "df = df.dropna(subset=[\"IDH2017\"])\n",
    "df = df.dropna(subset=[\"IDH2018\"])\n",
    "df = df.dropna(subset=[\"IDH2019\"])\n",
    "df = df.dropna(subset=[\"IDH2020\"])\n",
    "df = df.dropna(subset=[\"IDH2021\"])\n",
    "\n",
    "amazonia_legal = [\"AC\", \"AM\", \"AP\", \"MA\", \"MT\", \"PA\", \"RO\", \"RR\", \"TO\"]\n",
    "df= df[df[\"UF\"].isin(amazonia_legal)]\n",
    "\n",
    "\n",
    "# 7️⃣ Salvar versão agregada\n",
    "output = \"data/limpos/ipeadata_limpo.csv\"\n",
    "df.to_csv(output, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Base agregada por estado salva com sucesso!\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b58824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 📄 POPULACAO ===\n",
      "Colunas: ['UF', 'populacao']\n",
      "Tipos:\n",
      " UF            object\n",
      "populacao    float64\n",
      "dtype: object\n",
      "Amostra:\n",
      "   UF  populacao\n",
      "0  AC   906876.0\n",
      "1  AM  4269995.0\n",
      "2  AP   877613.0\n",
      "3  MA  7153262.0\n",
      "4  MT  3567234.0 \n",
      "\n",
      "\n",
      "=== 📄 DESMATAMENTO ===\n",
      "Colunas: ['UF', 'area_km']\n",
      "Tipos:\n",
      " UF          object\n",
      "area_km    float64\n",
      "dtype: object\n",
      "Amostra:\n",
      "   UF      area_km\n",
      "0  AC   892.610973\n",
      "1  AM  2167.098538\n",
      "2  AP    16.089385\n",
      "3  MA   318.482521\n",
      "4  MT  1972.025765 \n",
      "\n",
      "\n",
      "=== 📄 IPEADATA ===\n",
      "Colunas: ['UF', 'IDH']\n",
      "Tipos:\n",
      " UF      object\n",
      "IDH    float64\n",
      "dtype: object\n",
      "Amostra:\n",
      "   UF    IDH\n",
      "0  AC  0.710\n",
      "1  AM  0.700\n",
      "2  AP  0.688\n",
      "3  MA  0.676\n",
      "4  MT  0.736 \n",
      "\n",
      "\n",
      "=== 📄 PIB ===\n",
      "Colunas: ['UF', 'pib_mil_reais', 'pib_bilhoes']\n",
      "Tipos:\n",
      " UF                object\n",
      "pib_mil_reais    float64\n",
      "pib_bilhoes      float64\n",
      "dtype: object\n",
      "Amostra:\n",
      "   UF  pib_mil_reais  pib_bilhoes\n",
      "0  AC     21374442.0        21.37\n",
      "1  AM    131531039.0       131.53\n",
      "2  AP     20099850.0        20.10\n",
      "3  MA    124980727.0       124.98\n",
      "4  MT    233390206.0       233.39 \n",
      "\n",
      "\n",
      "=== 🧭 Colunas de identificação (UF / Estado) ===\n",
      "populacao: 'UF'\n",
      "desmatamento: 'UF'\n",
      "ipeadata: 'UF'\n",
      "pib: 'UF'\n",
      "\n",
      "=== 🗺️ Estados presentes em cada base ===\n",
      "populacao: ['AC', 'AM', 'AP', 'MA', 'MT', 'PA', 'RO', 'RR', 'TO']\n",
      "desmatamento: ['AC', 'AM', 'AP', 'MA', 'MT', 'PA', 'RO', 'RR', 'TO']\n",
      "ipeadata: ['AC', 'AM', 'AP', 'MA', 'MT', 'PA', 'RO', 'RR', 'TO']\n",
      "pib: ['AC', 'AM', 'AP', 'MA', 'MT', 'PA', 'RO', 'RR', 'TO']\n",
      "\n",
      "✅ Análise concluída!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho da pasta\n",
    "base_path = \"data/limpos/\"\n",
    "\n",
    "# Nomes dos arquivos\n",
    "arquivos = {\n",
    "    \"populacao\": \"br_ibge_populacao_estados_limpo.csv\",\n",
    "    \"desmatamento\": \"desmatamento_2021_por_estado.csv\",\n",
    "    \"ipeadata\": \"ipeadata_limpo.csv\",\n",
    "    \"pib\": \"pib_estadual_amazonia_2021.csv\"\n",
    "}\n",
    "\n",
    "# Função auxiliar pra exibir infos resumidas\n",
    "def mostrar_info(nome, df):\n",
    "    print(f\"\\n=== 📄 {nome.upper()} ===\")\n",
    "    print(\"Colunas:\", list(df.columns))\n",
    "    print(\"Tipos:\\n\", df.dtypes)\n",
    "    print(\"Amostra:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "# Ler e exibir informações de cada base\n",
    "bases = {}\n",
    "for nome, arquivo in arquivos.items():\n",
    "    caminho = os.path.join(base_path, arquivo)\n",
    "    df = pd.read_csv(caminho)\n",
    "    bases[nome] = df\n",
    "    mostrar_info(nome, df)\n",
    "\n",
    "# 🔎 Verificar colunas de identificação do estado\n",
    "print(\"\\n=== 🧭 Colunas de identificação (UF / Estado) ===\")\n",
    "for nome, df in bases.items():\n",
    "    for col in df.columns:\n",
    "        if \"uf\" in col.lower() or \"estado\" in col.lower():\n",
    "            print(f\"{nome}: '{col}'\")\n",
    "\n",
    "# 🔎 Verificar se todas as UFs estão na Amazônia Legal\n",
    "amazonia_legal = {\"AC\",\"AM\",\"AP\",\"MA\",\"MT\",\"PA\",\"RO\",\"RR\",\"TO\"}\n",
    "print(\"\\n=== 🗺️ Estados presentes em cada base ===\")\n",
    "for nome, df in bases.items():\n",
    "    uf_cols = [c for c in df.columns if \"uf\" in c.lower()]\n",
    "    if uf_cols:\n",
    "        print(f\"{nome}: {sorted(set(df[uf_cols[0]].unique()) & amazonia_legal)}\")\n",
    "\n",
    "print(\"\\n✅ Análise concluída!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf565e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base final criada com sucesso!\n",
      "   UF  populacao      area_km    IDH  pib_mil_reais  pib_bilhoes\n",
      "0  AC   906876.0   892.610973  0.710     21374442.0        21.37\n",
      "1  AM  4269995.0  2167.098538  0.700    131531039.0       131.53\n",
      "2  AP   877613.0    16.089385  0.688     20099850.0        20.10\n",
      "3  MA  7153262.0   318.482521  0.676    124980727.0       124.98\n",
      "4  MT  3567234.0  1972.025765  0.736    233390206.0       233.39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar todas as bases limpas\n",
    "pop = pd.read_csv(\"data/limpos/br_ibge_populacao_estados_limpo.csv\")\n",
    "desm = pd.read_csv(\"data/limpos/desmatamento_2021_por_estado.csv\")\n",
    "idh = pd.read_csv(\"data/limpos/ipeadata_limpo.csv\")\n",
    "pib = pd.read_csv(\"data/limpos/pib_estadual_amazonia_2021.csv\")\n",
    "\n",
    "# Merge progressivo por 'UF'\n",
    "df_final = pop.merge(desm, on=\"UF\") \\\n",
    "              .merge(idh, on=\"UF\") \\\n",
    "              .merge(pib, on=\"UF\")\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"✅ Base final criada com sucesso!\")\n",
    "print(df_final.head())\n",
    "\n",
    "# Salvar para uso no Scikit-Learn\n",
    "df_final.to_csv(\"data/limpos/base_final.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18becd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dimensões: (9, 6)\n",
      "🔹 Colunas e tipos de dados:\n",
      "UF                object\n",
      "populacao        float64\n",
      "area_km          float64\n",
      "IDH              float64\n",
      "pib_mil_reais    float64\n",
      "pib_bilhoes      float64\n",
      "dtype: object\n",
      "\n",
      "🔍 Valores nulos por coluna:\n",
      "UF               0\n",
      "populacao        0\n",
      "area_km          0\n",
      "IDH              0\n",
      "pib_mil_reais    0\n",
      "pib_bilhoes      0\n",
      "dtype: int64\n",
      "\n",
      "✅ Todas as variáveis numéricas estão prontas pro Scikit-Learn!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar a base final\n",
    "df = pd.read_csv(\"data/limpos/base_final.csv\")\n",
    "\n",
    "print(\"📊 Dimensões:\", df.shape)\n",
    "print(\"🔹 Colunas e tipos de dados:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n🔍 Valores nulos por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Conferir se todas as colunas numéricas são válidas\n",
    "if df.select_dtypes(include=[\"float64\", \"int64\"]).shape[1] == len(df.columns) - 1:\n",
    "    print(\"\\n✅ Todas as variáveis numéricas estão prontas pro Scikit-Learn!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Ainda há colunas não numéricas (verifique se o tipo 'object' aparece acima).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
